{
    "predict_exact_match": 31.7691,
    "predict_exact_match_for_ACE 2004": 14.9015,
    "predict_exact_match_for_ACE 2005_sample_15000": 22.6415,
    "predict_exact_match_for_ACE05": 11.7747,
    "predict_exact_match_for_ADE_corpus_sample_15000": 26.8692,
    "predict_exact_match_for_AnatEM": 36.9191,
    "predict_exact_match_for_Broad Tweet Corpus": 20.7,
    "predict_exact_match_for_CASIE": 4.1333,
    "predict_exact_match_for_CoNLL 2003_sample_15000": 35.2737,
    "predict_exact_match_for_EEA": 4.1652,
    "predict_exact_match_for_EET": 17.6023,
    "predict_exact_match_for_FabNER": 1.5504,
    "predict_exact_match_for_FindVehicle": 20.5804,
    "predict_exact_match_for_GENIA_NER": 9.3851,
    "predict_exact_match_for_GIDS": 18.0868,
    "predict_exact_match_for_HarveyNER": 75.2878,
    "predict_exact_match_for_MultiNERD": 35.52,
    "predict_exact_match_for_NER": 34.1575,
    "predict_exact_match_for_NYT11_sample_30000": 23.0352,
    "predict_exact_match_for_New-York-Times-RE": 41.84,
    "predict_exact_match_for_Ontonotes_sample_30000": 54.9504,
    "predict_exact_match_for_PHEE": 21.0744,
    "predict_exact_match_for_PolyglotNER": 29.91,
    "predict_exact_match_for_RE": 20.4187,
    "predict_exact_match_for_SciERC_sample_10000": 0.0,
    "predict_exact_match_for_TweetNER7_sample_15000": 0.6944,
    "predict_exact_match_for_WikiANN en": 24.84,
    "predict_exact_match_for_WikiNeural": 36.8285,
    "predict_exact_match_for_bc2gm": 42.9,
    "predict_exact_match_for_bc4chemd": 47.1514,
    "predict_exact_match_for_bc5cdr": 19.3663,
    "predict_exact_match_for_conll04_sample_5000": 25.0,
    "predict_exact_match_for_kbp37": 4.6696,
    "predict_exact_match_for_mit-movie": 31.6953,
    "predict_exact_match_for_mit-restaurant": 31.9079,
    "predict_exact_match_for_ncbi": 49.7872,
    "predict_exact_match_for_semval-RE": 5.5576,
    "predict_gen_len": 15.6904,
    "predict_global_step": 0,
    "predict_loss": 0.8542041778564453,
    "predict_rouge1": 66.2305,
    "predict_rouge1_for_ACE 2004": 59.6114,
    "predict_rouge1_for_ACE 2005_sample_15000": 60.4797,
    "predict_rouge1_for_ACE05": 30.2486,
    "predict_rouge1_for_ADE_corpus_sample_15000": 73.7259,
    "predict_rouge1_for_AnatEM": 64.3186,
    "predict_rouge1_for_Broad Tweet Corpus": 50.492,
    "predict_rouge1_for_CASIE": 40.0741,
    "predict_rouge1_for_CoNLL 2003_sample_15000": 67.766,
    "predict_rouge1_for_EEA": 42.3535,
    "predict_rouge1_for_EET": 54.8063,
    "predict_rouge1_for_FabNER": 59.205,
    "predict_rouge1_for_FindVehicle": 84.688,
    "predict_rouge1_for_GENIA_NER": 55.329,
    "predict_rouge1_for_GIDS": 71.7221,
    "predict_rouge1_for_HarveyNER": 81.9758,
    "predict_rouge1_for_MultiNERD": 69.443,
    "predict_rouge1_for_NER": 67.8537,
    "predict_rouge1_for_NYT11_sample_30000": 60.0849,
    "predict_rouge1_for_New-York-Times-RE": 77.1767,
    "predict_rouge1_for_Ontonotes_sample_30000": 78.888,
    "predict_rouge1_for_PHEE": 67.3091,
    "predict_rouge1_for_PolyglotNER": 50.4653,
    "predict_rouge1_for_RE": 59.6459,
    "predict_rouge1_for_SciERC_sample_10000": 39.2979,
    "predict_rouge1_for_TweetNER7_sample_15000": 41.2652,
    "predict_rouge1_for_WikiANN en": 68.5059,
    "predict_rouge1_for_WikiNeural": 62.8163,
    "predict_rouge1_for_bc2gm": 65.4635,
    "predict_rouge1_for_bc4chemd": 63.6852,
    "predict_rouge1_for_bc5cdr": 58.358,
    "predict_rouge1_for_conll04_sample_5000": 65.3333,
    "predict_rouge1_for_kbp37": 42.1431,
    "predict_rouge1_for_mit-movie": 76.6062,
    "predict_rouge1_for_mit-restaurant": 75.676,
    "predict_rouge1_for_ncbi": 72.2693,
    "predict_rouge1_for_semval-RE": 30.2691,
    "predict_rougeL": 65.2146,
    "predict_rougeL_for_ACE 2004": 56.3253,
    "predict_rougeL_for_ACE 2005_sample_15000": 57.8141,
    "predict_rougeL_for_ACE05": 29.4356,
    "predict_rougeL_for_ADE_corpus_sample_15000": 72.64,
    "predict_rougeL_for_AnatEM": 63.6755,
    "predict_rougeL_for_Broad Tweet Corpus": 49.7975,
    "predict_rougeL_for_CASIE": 38.3128,
    "predict_rougeL_for_CoNLL 2003_sample_15000": 64.1298,
    "predict_rougeL_for_EEA": 39.2503,
    "predict_rougeL_for_EET": 54.7852,
    "predict_rougeL_for_FabNER": 54.7083,
    "predict_rougeL_for_FindVehicle": 84.2063,
    "predict_rougeL_for_GENIA_NER": 49.4368,
    "predict_rougeL_for_GIDS": 70.9336,
    "predict_rougeL_for_HarveyNER": 81.7406,
    "predict_rougeL_for_MultiNERD": 68.9264,
    "predict_rougeL_for_NER": 66.9647,
    "predict_rougeL_for_NYT11_sample_30000": 58.698,
    "predict_rougeL_for_New-York-Times-RE": 72.8442,
    "predict_rougeL_for_Ontonotes_sample_30000": 77.9988,
    "predict_rougeL_for_PHEE": 65.8288,
    "predict_rougeL_for_PolyglotNER": 49.843,
    "predict_rougeL_for_RE": 57.8425,
    "predict_rougeL_for_SciERC_sample_10000": 35.8073,
    "predict_rougeL_for_TweetNER7_sample_15000": 39.3767,
    "predict_rougeL_for_WikiANN en": 67.8749,
    "predict_rougeL_for_WikiNeural": 62.3134,
    "predict_rougeL_for_bc2gm": 64.5055,
    "predict_rougeL_for_bc4chemd": 63.2508,
    "predict_rougeL_for_bc5cdr": 56.5716,
    "predict_rougeL_for_conll04_sample_5000": 64.1268,
    "predict_rougeL_for_kbp37": 41.3701,
    "predict_rougeL_for_mit-movie": 75.3554,
    "predict_rougeL_for_mit-restaurant": 74.6255,
    "predict_rougeL_for_ncbi": 71.7175,
    "predict_rougeL_for_semval-RE": 30.2334,
    "predict_runtime": 6373.3023,
    "predict_samples": 151084,
    "predict_samples_per_second": 23.706,
    "predict_steps_per_second": 1.482
}